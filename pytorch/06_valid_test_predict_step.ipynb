{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0655b3df-bd01-41a6-88f9-8cb97bf10215",
   "metadata": {},
   "source": [
    "\n",
    "## extra step 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0cd5e-2472-4fa2-8785-702749ec8e83",
   "metadata": {},
   "source": [
    "여태까지 Lightning moudle 을 상속받아 다음을 재구성하여 모델을 생성해보았다\n",
    "\n",
    "- \\_\\_init\\_\\_() : 신경망을 구성하는데 사용 (layer 정의)\n",
    "- forward() : 실제로 신경망에 x 가 들어갔을 때 나오는 y 를 정의 -> 실제로 call 은 forward를 부르는게 아니라 오브젝트를 call 해야함 (나중에 hook등이 동작하게 하기 위해서)\n",
    "- traning_step : 데이터를 넣었을 때, loss 를 계산하는 방법을 정의 (따라서 traning step 내부에는 당연히 forward 가 포함된 model() call이 있어야 한다) 하고 loss 를 리턴한다.\n",
    "- validation_step : validation 방법을 정의한다. 별도의 return 은 없어도 된다. (없어도 모델은 돌아감)\n",
    "- test_step : test 방법을 정의한다. 별도의 return 은 없어도 된다.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747d133-2d63-4416-8863-fe509e88dcf6",
   "metadata": {},
   "source": [
    "이를 활용한 기본 모델의 뼈대는 아래와 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d1132f5-652f-4860-8b48-4343933e1cb0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## 1~5 장까지 실습한 내용\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.accelerators import accelerator\n",
    "from torchmetrics import functional as FM\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(28*28, 32)\n",
    "        self.dense2 = nn.Linear(28*28, 32)\n",
    "        self.dense2_2= nn.Linear(32, 16)\n",
    "        self.dense3 = nn.Linear(32+16, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x1 = self.dense1(x)\n",
    "        x1 = self.relu(x1)\n",
    "\n",
    "        x2_1 = self.dense2(x)\n",
    "        x2_1 = self.relu(x2_1)\n",
    "        x2_2 = self.dense2_2(x2_1)\n",
    "        x2_2 = self.relu(x2_2)\n",
    "\n",
    "        x = torch.cat([x1, x2_2], dim=1)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return(x)\n",
    "        \n",
    "\n",
    "\n",
    "def dataLoader(batch_size=128):\n",
    "    train_dataset = MNIST('', transform=transforms.ToTensor(), train=True, download=True) ## 한 번 인터넷으로 가져온걸 매번 가져올 필요가 없기 때문에 가져올때 download True 로 하면 다음 부터는 다운로드 된 데이터를 사용한다.\n",
    "    test_dataset = MNIST('', transform=transforms.ToTensor(), train=False, download=True)\n",
    "    trainDataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valDataLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return (trainDataLoader,valDataLoader)\n",
    "\n",
    "trainDataLoader,valDataLoader = dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ce75ad-f2c4-4520-b2f6-49e2f0539a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\msong\\miniconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type  | Params\n",
      "---------------------------------\n",
      "0 | layers | Model | 51.3 K\n",
      "---------------------------------\n",
      "51.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.3 K    Total params\n",
      "0.205     Total estimated model params size (MB)\n",
      "C:\\Users\\msong\\miniconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c65243434b4a7085e9861643df1f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layers =  Model()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "        acc = FM.accuracy(y_pred, y, task=\"multiclass\",num_classes=10)\n",
    "        mse = FM.mean_squared_error(torch.argmax(y_pred, dim=1), y)\n",
    "        metrics={'loss': loss, 'acc':acc, 'mse': mse}\n",
    "        self.log_dict(metrics,prog_bar=True)#on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = loss_function(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y, task=\"multiclass\",num_classes=10)\n",
    "        mse = FM.mean_squared_error(torch.argmax(y_hat, dim=1), y)\n",
    "        metrics={'val_loss': loss, 'val_acc':acc, 'val_mse': mse}\n",
    "        self.log_dict(metrics) #on_step=False, on_epoch=True\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = loss_function(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y, task=\"multiclass\",num_classes=10)\n",
    "        metrics={'test_loss': loss, 'test_acc':acc}\n",
    "        self.log_dict(metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "model = MyModel()\n",
    "#summary(model, input_size=(8, 1, 28, 28))\n",
    "\n",
    "epochs=3\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator='auto')\n",
    "trainer.fit(model, trainDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c2c8e-00f6-40e4-a629-718e1f37d27b",
   "metadata": {},
   "source": [
    "validation step 과 test step 이 모두 정의가 되었기 때문에 아래와 같이 valdiate 나 test 메쏘드를 사용가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2768095-5bf0-4f72-b527-92bd053d5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\msong\\miniconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc3a83e610d4e65a29f22b39855ccd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Runningstage.validating metric      DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.9506000280380249\n",
      "        val_loss            0.16787856817245483\n",
      "         val_mse            0.8942999839782715\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.16787856817245483,\n",
       "  'val_acc': 0.9506000280380249,\n",
       "  'val_mse': 0.8942999839782715}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, valDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5689f7-fd74-42f3-8f44-a39c313132ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\msong\\miniconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f8a6e1f951454699b22493972e9d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Runningstage.testing metric      DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9506000280380249\n",
      "        test_loss           0.16787856817245483\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.16787856817245483, 'test_acc': 0.9506000280380249}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, valDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5c134-c6c3-4485-ba92-3eea69005d79",
   "metadata": {},
   "source": [
    "또한 별도의 forward() 를 이용하여 학습된 모델을 실행하는 별도의 process 를 생성할 수 도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef461a8c-6b02-431f-b662-06b665acda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class altModel(MyModel):\n",
    "\n",
    "    def predict_step(self, x, batch_idx):\n",
    "        y_pred = self(x) ## < forward 에 x를 넣어서 나온 결과 ==> logit 상태임\n",
    "        y_pb = nn.Softmax(y_pred) ## logit 을 Softmax 취해서 확률로 바꿈\n",
    "        return y_pb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07342d7c-5d02-46de-a86e-09357063cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = altModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06fa6212-aa9d-4053-96e2-829689990409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type  | Params\n",
      "---------------------------------\n",
      "0 | layers | Model | 51.3 K\n",
      "---------------------------------\n",
      "51.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.3 K    Total params\n",
      "0.205     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba479e76069b4827ba4842dfd2db65de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=3\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator='auto')\n",
    "trainer.fit(model, trainDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46e2d882-5c3f-4f0c-b9a1-f577676cefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valDataLoader)) ##  데이터 로더에서 1개 배치 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2ba069b-1735-4a05-8fc1-e52b04f3c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0].shape) # x \n",
    "print(batch[1].shape) # y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb0375-bab4-4a27-8c46-7bf37e23aa4e",
   "metadata": {},
   "source": [
    "배치사이즈가 128개씩 이므로 이중에서 가장 첫번째 x 만 보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dd8918d-dd94-484b-b7b9-19aae9287ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x247a5a43390>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbKUlEQVR4nO3df3DU9b3v8dcCyQqYbAwh2UQCBvxBFUinFNJclMaSS4hnGFDOHVBvBxwvXGlwhNTqiaMgbeemxTno0UPxnxbqGQHLuQJHTi8djSaMbYKHKIfLtWZIJhYYklBzD9kQJATyuX9wXV1JwO+ym3eyPB8z3xmy+/3k+/br6pNvsvnG55xzAgBggA2zHgAAcH0iQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQI6wG+rre3VydPnlRKSop8Pp/1OAAAj5xz6uzsVE5OjoYN6/86Z9AF6OTJk8rNzbUeAwBwjY4fP65x48b1+/ygC1BKSook6W7dpxFKMp4GAODVBfXoff0+/P/z/sQtQJs2bdILL7yg1tZW5efn65VXXtHMmTOvuu6LL7uNUJJG+AgQAAw5//8Oo1f7Nkpc3oTwxhtvqLy8XOvWrdOHH36o/Px8lZSU6NSpU/E4HABgCIpLgDZu3Kjly5frkUce0Z133qlXX31Vo0aN0m9+85t4HA4AMATFPEDnz59XfX29iouLvzzIsGEqLi5WbW3tZft3d3crFApFbACAxBfzAH322We6ePGisrKyIh7PyspSa2vrZftXVlYqEAiEN94BBwDXB/MfRK2oqFBHR0d4O378uPVIAIABEPN3wWVkZGj48OFqa2uLeLytrU3BYPCy/f1+v/x+f6zHAAAMcjG/AkpOTtb06dNVVVUVfqy3t1dVVVUqLCyM9eEAAENUXH4OqLy8XEuXLtV3v/tdzZw5Uy+99JK6urr0yCOPxONwAIAhKC4BWrx4sf76179q7dq1am1t1be//W3t27fvsjcmAACuXz7nnLMe4qtCoZACgYCKtIA7IQDAEHTB9ahae9TR0aHU1NR+9zN/FxwA4PpEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxDxAzz//vHw+X8Q2efLkWB8GADDEjYjHJ73rrrv0zjvvfHmQEXE5DABgCItLGUaMGKFgMBiPTw0ASBBx+R7Q0aNHlZOTo4kTJ+rhhx/WsWPH+t23u7tboVAoYgMAJL6YB6igoEBbt27Vvn37tHnzZjU3N+uee+5RZ2dnn/tXVlYqEAiEt9zc3FiPBAAYhHzOORfPA5w+fVoTJkzQxo0b9eijj172fHd3t7q7u8Mfh0Ih5ebmqkgLNMKXFM/RAABxcMH1qFp71NHRodTU1H73i/u7A9LS0nT77bersbGxz+f9fr/8fn+8xwAADDJx/zmgM2fOqKmpSdnZ2fE+FABgCIl5gJ588knV1NTo008/1Z/+9Cfdf//9Gj58uB588MFYHwoAMITF/EtwJ06c0IMPPqj29naNHTtWd999t+rq6jR27NhYHwoAMITFPEA7duyI9acEACQg7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI+y+kw8BqX17oec34H/b9ywKv5pNTWZ7XnO/2/ltub97ufc2oE2c8r5Gk3kMfR7UOgHdcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEd8NOME/9ZJvnNYtG/0d0B5sU3TLPirwv+fTC2agO9Q9/vTeqdRg4H5ya4HnN6L8PRHWsEVX1Ua3DN8MVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRJpiXn1niec3aadH9PeSmPzvPa/7jWz7Pa5Knnfa8ZsOUNz2vkaQXsw94XvOvZ2/0vOZvRp3xvGYgfe7Oe15zoHu05zVFN/R4XqMo/h3duvi/ez+OpNurolqGb4grIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjTTCj/9n7jRpH/3McBulH6gAd55VgUVTrfj7rFs9rUmsaPa/ZUHSr5zUDacTnvZ7XjD7c4nnNmP3/0/OaqclJnteM+tT7GsQfV0AAABMECABgwnOA9u/fr/nz5ysnJ0c+n0+7d++OeN45p7Vr1yo7O1sjR45UcXGxjh49Gqt5AQAJwnOAurq6lJ+fr02bNvX5/IYNG/Tyyy/r1Vdf1YEDBzR69GiVlJTo3Llz1zwsACBxeH4TQmlpqUpLS/t8zjmnl156Sc8++6wWLFggSXrttdeUlZWl3bt3a8kS77+tEwCQmGL6PaDm5ma1traquLg4/FggEFBBQYFqa2v7XNPd3a1QKBSxAQASX0wD1NraKknKysqKeDwrKyv83NdVVlYqEAiEt9zc3FiOBAAYpMzfBVdRUaGOjo7wdvz4ceuRAAADIKYBCgaDkqS2traIx9va2sLPfZ3f71dqamrEBgBIfDENUF5enoLBoKqqqsKPhUIhHThwQIWFhbE8FABgiPP8LrgzZ86osfHLW480Nzfr0KFDSk9P1/jx47V69Wr9/Oc/12233aa8vDw999xzysnJ0cKFC2M5NwBgiPMcoIMHD+ree+8Nf1xeXi5JWrp0qbZu3aqnnnpKXV1dWrFihU6fPq27775b+/bt0w033BC7qQEAQ57POeesh/iqUCikQCCgIi3QCB83EASGivb/5v3L7LXr/9Hzmo3/d7LnNfvnTvK8RpIutPT97l1c2QXXo2rtUUdHxxW/r2/+LjgAwPWJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJjz/OgYAiW/EhFzPa/7xGe93tk7yDfe8Zuc/FHteM6al1vMaxB9XQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCuAyn6y52fOaGX6f5zX/5/znntekf3zW8xoMTlwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpkMC6/2ZGVOs+/NsXo1jl97xi5RNPeF4z8k8feF6DwYkrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBRLYsdLo/o55o8/7jUUfbP7PnteM2vfvntc4zyswWHEFBAAwQYAAACY8B2j//v2aP3++cnJy5PP5tHv37ojnly1bJp/PF7HNmzcvVvMCABKE5wB1dXUpPz9fmzZt6nefefPmqaWlJbxt3779moYEACQez29CKC0tVWlp6RX38fv9CgaDUQ8FAEh8cfkeUHV1tTIzM3XHHXdo5cqVam9v73ff7u5uhUKhiA0AkPhiHqB58+bptddeU1VVlX75y1+qpqZGpaWlunjxYp/7V1ZWKhAIhLfc3NxYjwQAGIRi/nNAS5YsCf956tSpmjZtmiZNmqTq6mrNmTPnsv0rKipUXl4e/jgUChEhALgOxP1t2BMnTlRGRoYaGxv7fN7v9ys1NTViAwAkvrgH6MSJE2pvb1d2dna8DwUAGEI8fwnuzJkzEVczzc3NOnTokNLT05Wenq7169dr0aJFCgaDampq0lNPPaVbb71VJSUlMR0cADC0eQ7QwYMHde+994Y//uL7N0uXLtXmzZt1+PBh/fa3v9Xp06eVk5OjuXPn6mc/+5n8fu/3lgIAJC7PASoqKpJz/d8O8A9/+MM1DQSgb8NSUjyv+eE970d1rFDvOc9rTv2PiZ7X+Lv/zfMaJA7uBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATMf+V3ADi4+jzd3leszfjV1Eda8HRRZ7X+H/Pna3hDVdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKGOj4r9/zvObw4pc9r2m60ON5jSSd+eU4z2v8aonqWLh+cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTANRpxc47nNaufe8PzGr/P+3+uS/79h57XSNLY//VvUa0DvOAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1Iga/wjfD+n0T+3hOe1/yXG9s9r3m9M9Pzmqznovs7Zm9UqwBvuAICAJggQAAAE54CVFlZqRkzZiglJUWZmZlauHChGhoaIvY5d+6cysrKNGbMGN14441atGiR2traYjo0AGDo8xSgmpoalZWVqa6uTm+//bZ6eno0d+5cdXV1hfdZs2aN3nrrLe3cuVM1NTU6efKkHnjggZgPDgAY2jx9x3Xfvn0RH2/dulWZmZmqr6/X7Nmz1dHRoV//+tfatm2bfvCDH0iStmzZom9961uqq6vT9773vdhNDgAY0q7pe0AdHR2SpPT0dElSfX29enp6VFxcHN5n8uTJGj9+vGpra/v8HN3d3QqFQhEbACDxRR2g3t5erV69WrNmzdKUKVMkSa2trUpOTlZaWlrEvllZWWptbe3z81RWVioQCIS33NzcaEcCAAwhUQeorKxMR44c0Y4dO65pgIqKCnV0dIS348ePX9PnAwAMDVH9IOqqVau0d+9e7d+/X+PGjQs/HgwGdf78eZ0+fTriKqitrU3BYLDPz+X3++X3+6MZAwAwhHm6AnLOadWqVdq1a5feffdd5eXlRTw/ffp0JSUlqaqqKvxYQ0ODjh07psLCwthMDABICJ6ugMrKyrRt2zbt2bNHKSkp4e/rBAIBjRw5UoFAQI8++qjKy8uVnp6u1NRUPf744yosLOQdcACACJ4CtHnzZklSUVFRxONbtmzRsmXLJEkvvviihg0bpkWLFqm7u1slJSX61a9+FZNhAQCJw+ecc9ZDfFUoFFIgEFCRFmiEL8l6HFxnfNPv8rzmX//ln+IwyeX+U0WZ5zVpr/X94w9APF1wParWHnV0dCg1NbXf/bgXHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExE9RtRgcFu+J23R7VuxY49MZ6kb3f+xvudrW/5p7o4TALY4QoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUiRkD750U1RrZs/KhTjSfo2rvq890XOxX4QwBBXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GikHv3PyZntdUzf/7KI82Ksp1ALziCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSDHonZw13POa8SMG7qair3dmel6TFDrveY3zvAIY3LgCAgCYIEAAABOeAlRZWakZM2YoJSVFmZmZWrhwoRoaGiL2KSoqks/ni9gee+yxmA4NABj6PAWopqZGZWVlqqur09tvv62enh7NnTtXXV1dEfstX75cLS0t4W3Dhg0xHRoAMPR5ehPCvn37Ij7eunWrMjMzVV9fr9mzZ4cfHzVqlILBYGwmBAAkpGv6HlBHR4ckKT09PeLx119/XRkZGZoyZYoqKip09uzZfj9Hd3e3QqFQxAYASHxRvw27t7dXq1ev1qxZszRlypTw4w899JAmTJignJwcHT58WE8//bQaGhr05ptv9vl5KisrtX79+mjHAAAMUVEHqKysTEeOHNH7778f8fiKFSvCf546daqys7M1Z84cNTU1adKkSZd9noqKCpWXl4c/DoVCys3NjXYsAMAQEVWAVq1apb1792r//v0aN27cFfctKCiQJDU2NvYZIL/fL7/fH80YAIAhzFOAnHN6/PHHtWvXLlVXVysvL++qaw4dOiRJys7OjmpAAEBi8hSgsrIybdu2TXv27FFKSopaW1slSYFAQCNHjlRTU5O2bdum++67T2PGjNHhw4e1Zs0azZ49W9OmTYvLPwAAYGjyFKDNmzdLuvTDpl+1ZcsWLVu2TMnJyXrnnXf00ksvqaurS7m5uVq0aJGeffbZmA0MAEgMnr8EdyW5ubmqqam5poEAANcH7oYNfEVl+52e19SW3OJ5jWv5357XAImGm5ECAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSkGvYl/V+t5zX1/9504TNKf1gE8FpA4uAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgYtDdC845J0m6oB7JGQ8DAPDsgnokffn/8/4MugB1dnZKkt7X740nAQBci87OTgUCgX6f97mrJWqA9fb26uTJk0pJSZHP54t4LhQKKTc3V8ePH1dqaqrRhPY4D5dwHi7hPFzCebhkMJwH55w6OzuVk5OjYcP6/07PoLsCGjZsmMaNG3fFfVJTU6/rF9gXOA+XcB4u4Txcwnm4xPo8XOnK5wu8CQEAYIIAAQBMDKkA+f1+rVu3Tn6/33oUU5yHSzgPl3AeLuE8XDKUzsOgexMCAOD6MKSugAAAiYMAAQBMECAAgAkCBAAwMWQCtGnTJt1yyy264YYbVFBQoA8++MB6pAH3/PPPy+fzRWyTJ0+2Hivu9u/fr/nz5ysnJ0c+n0+7d++OeN45p7Vr1yo7O1sjR45UcXGxjh49ajNsHF3tPCxbtuyy18e8efNsho2TyspKzZgxQykpKcrMzNTChQvV0NAQsc+5c+dUVlamMWPG6MYbb9SiRYvU1tZmNHF8fJPzUFRUdNnr4bHHHjOauG9DIkBvvPGGysvLtW7dOn344YfKz89XSUmJTp06ZT3agLvrrrvU0tIS3t5//33rkeKuq6tL+fn52rRpU5/Pb9iwQS+//LJeffVVHThwQKNHj1ZJSYnOnTs3wJPG19XOgyTNmzcv4vWxffv2AZww/mpqalRWVqa6ujq9/fbb6unp0dy5c9XV1RXeZ82aNXrrrbe0c+dO1dTU6OTJk3rggQcMp469b3IeJGn58uURr4cNGzYYTdwPNwTMnDnTlZWVhT++ePGiy8nJcZWVlYZTDbx169a5/Px86zFMSXK7du0Kf9zb2+uCwaB74YUXwo+dPn3a+f1+t337doMJB8bXz4Nzzi1dutQtWLDAZB4rp06dcpJcTU2Nc+7Sv/ukpCS3c+fO8D5//vOfnSRXW1trNWbcff08OOfc97//fffEE0/YDfUNDPoroPPnz6u+vl7FxcXhx4YNG6bi4mLV1tYaTmbj6NGjysnJ0cSJE/Xwww/r2LFj1iOZam5uVmtra8TrIxAIqKCg4Lp8fVRXVyszM1N33HGHVq5cqfb2duuR4qqjo0OSlJ6eLkmqr69XT09PxOth8uTJGj9+fEK/Hr5+Hr7w+uuvKyMjQ1OmTFFFRYXOnj1rMV6/Bt3NSL/us88+08WLF5WVlRXxeFZWlj755BOjqWwUFBRo69atuuOOO9TS0qL169frnnvu0ZEjR5SSkmI9nonW1lZJ6vP18cVz14t58+bpgQceUF5enpqamvTMM8+otLRUtbW1Gj58uPV4Mdfb26vVq1dr1qxZmjJliqRLr4fk5GSlpaVF7JvIr4e+zoMkPfTQQ5owYYJycnJ0+PBhPf3002poaNCbb75pOG2kQR8gfKm0tDT852nTpqmgoEATJkzQ7373Oz366KOGk2EwWLJkSfjPU6dO1bRp0zRp0iRVV1drzpw5hpPFR1lZmY4cOXJdfB/0Svo7DytWrAj/eerUqcrOztacOXPU1NSkSZMmDfSYfRr0X4LLyMjQ8OHDL3sXS1tbm4LBoNFUg0NaWppuv/12NTY2Wo9i5ovXAK+Py02cOFEZGRkJ+fpYtWqV9u7dq/feey/i17cEg0GdP39ep0+fjtg/UV8P/Z2HvhQUFEjSoHo9DPoAJScna/r06aqqqgo/1tvbq6qqKhUWFhpOZu/MmTNqampSdna29Shm8vLyFAwGI14foVBIBw4cuO5fHydOnFB7e3tCvT6cc1q1apV27dqld999V3l5eRHPT58+XUlJSRGvh4aGBh07diyhXg9XOw99OXTokCQNrteD9bsgvokdO3Y4v9/vtm7d6j7++GO3YsUKl5aW5lpbW61HG1A//vGPXXV1tWtubnZ//OMfXXFxscvIyHCnTp2yHi2uOjs73UcffeQ++ugjJ8lt3LjRffTRR+4vf/mLc865X/ziFy4tLc3t2bPHHT582C1YsMDl5eW5zz//3Hjy2LrSeejs7HRPPvmkq62tdc3Nze6dd95x3/nOd9xtt93mzp07Zz16zKxcudIFAgFXXV3tWlpawtvZs2fD+zz22GNu/Pjx7t1333UHDx50hYWFrrCw0HDq2LvaeWhsbHQ//elP3cGDB11zc7Pbs2ePmzhxops9e7bx5JGGRICcc+6VV15x48ePd8nJyW7mzJmurq7OeqQBt3jxYpedne2Sk5PdzTff7BYvXuwaGxutx4q79957z0m6bFu6dKlz7tJbsZ977jmXlZXl/H6/mzNnjmtoaLAdOg6udB7Onj3r5s6d68aOHeuSkpLchAkT3PLlyxPuL2l9/fNLclu2bAnv8/nnn7sf/ehH7qabbnKjRo1y999/v2tpabEbOg6udh6OHTvmZs+e7dLT053f73e33nqr+8lPfuI6OjpsB/8afh0DAMDEoP8eEAAgMREgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJv4fx1BnJzDsp98AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6b903-83bd-4292-a8c7-6bd0b0852048",
   "metadata": {},
   "source": [
    "위와 같은 글씨임을 알 수 있다. 이걸 실제 모델에 넣어서 forward 시켜보면 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82f35721-7eab-4d96-9409-94705db87cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logit = model(batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e084c5f-01d0-4522-96b2-2026fbf14db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -1.9990,  -8.6402,   1.3585,   2.4129,  -6.7126,  -1.5154, -11.8695,\n",
       "          8.9260,  -3.0257,  -0.7638], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_logit.shape\n",
    "y_logit[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa901579-6237-412e-ab33-787bb9271b99",
   "metadata": {},
   "source": [
    "위와 같은 logit 값을 볼 수 있는데, 여기에 softmax 를 취해서 변화하는게 바로 각 class 에 해당하는 probability 이므로 이걸 정의한게 위의 predict 매쏘드이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab17dd7-1106-4028-9009-fc4762aad495",
   "metadata": {},
   "source": [
    "따라서 model 에 batch 를 넣으면 logit 에 해당하는 값을 얻을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3badb2e1-85a2-4627-ab77-5dbccb6e24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predcit_with_logit = model(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef2163-4d18-4f80-a6dd-a85dd46a265e",
   "metadata": {},
   "source": [
    "하지만 보통 대부분의 경우 우리가 관심이 있는 값들은 logit 이 아니라 이걸 확률로 변환한 prob 값인데, 우리가 predict_step 에 대해 정의를 했기 때문에, 이제 Trainer  에서도 predict를 사용할 수 있다. (model 에서 predict_step 이 정의가 되었기 때문에 활용가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "353363ae-179f-4410-8f50-f11138622514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df198340bed443ba9317d54d06c0d259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict_with_prob = trainer.predict(model, batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0afdfc9-269e-4a15-98a9-1ae589ba59be",
   "metadata": {},
   "source": [
    "단 주의할점이 있는데, predict step 의 결과는 Softmax를 취한 logit 자체이지, 그 값이 아니다. 이해하기 힘들겠지만, 아래 결과를 보면 logit으로 나온 값을 보면 모델을 통과한 뒤에 각 class 에 해당하는 어떤 계산 값들이다. 반면 우리가 predict 한 값은 여기에 Softmax layer를 취해야 한다는걸 알려주지, 그 값을 알려주지는 않는다. (물론 나중에 여기에 argmax 등을 할 때에는 softmax를 취한 값의 argmax가 취해진다. -> 지금은 이해가 안되도 넘어가도록 하자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aba9be02-9f0f-478b-87d2-7b0061980600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -1.9990,  -8.6403,   1.3585,   2.4129,  -6.7126,  -1.5154, -11.8695,\n",
      "          8.9260,  -3.0257,  -0.7638], grad_fn=<SelectBackward0>)\n",
      "Softmax(\n",
      "  dim=tensor([[ -1.9990,  -8.6403,   1.3585,   2.4129,  -6.7126,  -1.5154, -11.8695,\n",
      "             8.9260,  -3.0257,  -0.7638]], device='cuda:0')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(y_predcit_with_logit[0])\n",
    "print(y_predict_with_prob[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ad307-a1e5-4923-b4ff-c291f34f0154",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a624cf0e-b87e-4aed-a94e-fbb470b892f7",
   "metadata": {},
   "source": [
    "그럼 실제로 추론하는 과정을 대략적으로 이해해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "83dd6794-7453-48d5-b7f1-c74e22c5136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n",
      "tensor([ -1.9990,  -8.6403,   1.3585,   2.4129,  -6.7126,  -1.5154, -11.8695,\n",
      "          8.9260,  -3.0257,  -0.7638], grad_fn=<SliceBackward0>)\n",
      "----\n",
      "tensor([ -1.9990,  -8.6403,   1.3585,   2.4129,  -6.7126,  -1.5154, -11.8695,\n",
      "          8.9260,  -3.0257,  -0.7638])\n",
      "----\n",
      "tensor([1.7965e-05, 2.3452e-08, 5.1593e-04, 1.4808e-03, 1.6119e-07, 2.9138e-05,\n",
      "        9.2838e-10, 9.9789e-01, 6.4346e-06, 6.1784e-05])\n",
      "----\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(valDataLoader))  ## 데이터로더로부터 다음의 batch 를 가져온다.\n",
    "\n",
    "model.eval() ## evaluation mode로 바꾼다. (drop out, batch normalization 등)\n",
    "\n",
    "y_pred = model(batch[0]) # batch 의 x 가 들어간다. input(128, 1, 28, 28) -> output (128, 10)\n",
    "\n",
    "print(y_pred.size()) ## tensor with 128 x 10\n",
    "print(y_pred[0, :])  ## 그 중 첫번째의 logit values, numpy 와 비슷하지만 뒤에 grad 정보가 있기 때문에 바로 그리거나 할 수 는 없음 이를 detach\n",
    "\n",
    "print(\"----\")\n",
    "# 주의 np.argmax( y_predict[0, :] ) 불가\n",
    "print(y_pred[0, :].detach())  ## grad_fn 부분이 사라진다.\n",
    "print(\"----\")\n",
    "softmax =  nn.Softmax(dim=0) \n",
    "print( softmax( y_pred[0, :].detach()  )) \n",
    "print(\"----\")\n",
    "print(np.argmax(softmax( y_pred[0, :].detach() ))) ## 이중 최대값의 argmax \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc076f06-3aeb-44c1-b315-ef13808c47e3",
   "metadata": {},
   "source": [
    "위와 같이 이루어진다고 보면 된다. 단 여기서 grad 가 포함되어 있는 Tensor는 일반적인 numpy 연산이 안되기 때문에 grad 부분을 때주는 detach를 해주거나 아니면 아래처럼 no_grad 옵션을 줘야한다.  (아래 예제코드의 경우 : 사실 제대로 하면 softmax를 취한 다음에 argmax를 해야하지만 일반적으로 logit 이 최고인 값이 softmax도 최고이기 때문에 확률로 변환된 값이 필요한게 아니라면(그냥 최대값만 보고 싶으면) 여기서 바로 argmax 해도 된다)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "44a10b5c-f386-4844-b2cb-efed7ea356c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.9990,  -8.6403,   1.3585,  ...,   8.9260,  -3.0257,  -0.7638],\n",
      "        [  0.1254,  -1.5450,   6.8217,  ..., -12.3396,  -0.9260,  -8.7171],\n",
      "        [ -5.1869,   5.5554,  -0.1129,  ...,  -0.3302,  -1.3250,  -4.0489],\n",
      "        ...,\n",
      "        [ -8.0665,  -3.4997,  -0.8681,  ...,  -1.4528,  -1.7214,   2.7112],\n",
      "        [  4.5235,  -6.4920,   0.7036,  ...,  -3.0617,  -2.1172,   0.8550],\n",
      "        [ -2.1980,  -4.6622,  -3.5125,  ...,  -9.0685,   0.0601,  -3.7213]]) \n",
      "\n",
      "tensor([ -1.9990,  -8.6403,   1.3585,   2.4129,  -6.7126,  -1.5154, -11.8695,\n",
      "          8.9260,  -3.0257,  -0.7638]) \n",
      "\n",
      "7 np\n",
      "tensor(7) tensor\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(valDataLoader)) # ((128,1,28,28),(128,10))\n",
    "## Sets the module in evaluation mode.(Dropout,BN,..)\n",
    "model.eval()\n",
    "\n",
    "## disabled gradient calculation.(reduce memory)\n",
    "with torch.no_grad():             ### w/o grad_fn object ###\n",
    "    y_predict = model(batch[0])   # model <- image only\n",
    "\n",
    "## y_predict 는 이제 grad 가 없는 상태임\n",
    "\n",
    "print(y_predict,'\\n')                 # (128,10) tensor, w/o grad_fn\n",
    "print(y_predict[0,:],'\\n')            # (10,)    tensor, w/o grad_fn\n",
    "print(np.argmax(y_predict[0,:].numpy()),'np') # numpy index\n",
    "print(np.argmax(y_predict[0,:]),'tensor') # tensor index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e98ee0d-b530-4ea5-b060-8f539cc9f56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5] ndarray\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model(batch[0]).detach(),axis=1).numpy(),'ndarray')  # 예측한 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "45a4c7b4-04e2-433f-9278-cd1c97400de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
      "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
      "        1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2,\n",
      "        5, 4, 7, 6, 7, 9, 0, 5]) Tensor\n"
     ]
    }
   ],
   "source": [
    "print(batch[1],'Tensor') # 정답 Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d7c80-c178-453f-a67b-f154ea46478c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
