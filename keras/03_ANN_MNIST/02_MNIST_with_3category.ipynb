{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75619abb-d2c4-43ed-8c4a-361ac61a53a5",
   "metadata": {},
   "source": [
    "## 숫자 2개를 구분했으니 3개도 가능하겠지?\n",
    "\n",
    "3, 8, 9 를 분류하는 딥러닝 모델을 만들어보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8e2430-9777-43ca-935c-943f3cee42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47cec43-3b31-4b4c-934b-fc1b2535317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196a1495-1cc1-44c9-9bb9-98baeb88ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cf98a-e072-4b82-98e7-f5e913f6f55f",
   "metadata": {},
   "source": [
    "데이터를 로드하기, 0-9 까지 있는데, 우리는 이중에서 3, 8, 9 이렇게 3개만 사용할테니, 데이터의 숫자는 1/3정도로 줄어들게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d305e0a4-087d-4c99-b346-43bdf333c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3,8,9 구분하기 \n",
    "three_eight_nine_train_idx = ((y_train == 3) | (y_train == 8) | (y_train == 9))\n",
    "x_train = x_train[three_eight_nine_train_idx]\n",
    "y_train = y_train[three_eight_nine_train_idx]\n",
    "\n",
    "three_eight_nine_test_idx  = ( (y_test==3) | (y_test==8) | (y_test==9) )\n",
    "x_test = x_test[three_eight_nine_test_idx]\n",
    "y_test = y_test[three_eight_nine_test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd38d5-0096-4aa2-812b-a94485d06b4a",
   "metadata": {},
   "source": [
    "앞에서 보았듯이 scaling을 하고 안하고에 따라 성능차이가 다소 발생하므로 0~1 로 스케일링을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aace599d-c7f3-45a8-95dd-a7652193c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e87e14-26ba-43a2-8b63-9c08deab50dc",
   "metadata": {},
   "source": [
    "간단한 모델을 만들어보자, activation 없이 그냥 3개 layer를 fully connected 해서 모델을 만들었다. 마지막 출력층은 실수값 1개로 출력받고, 이 최종 출력이 y값과 비슷하게 만드는게 목적!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396a8ddb-72f2-4a32-bc7b-665220157bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52353 (204.50 KB)\n",
      "Trainable params: 52353 (204.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dense(32), ## change it later\n",
    "        keras.layers.Dense(1)\n",
    "    ]           \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49029abc-2afb-4f19-b2d6-b057314197d3",
   "metadata": {},
   "source": [
    "이번에도 Loss 는 mse 를 설정하였다. 다만 조금있다 리뷰하겠지만 사실 mse 자체를 좋은 loss 라고 하기에는 좀 그렇다. \n",
    "일단 optimizer 와 loss 를 지난 8-9 분류할때와 같이 셋업하고 돌려보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb882bd5-6b6c-4197-b35c-4ea44c1d7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "505/505 [==============================] - 1s 964us/step - loss: 3.5125 - val_loss: 2.2859\n",
      "Epoch 2/20\n",
      "505/505 [==============================] - 0s 742us/step - loss: 2.0808 - val_loss: 1.7084\n",
      "Epoch 3/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 1.7932 - val_loss: 1.7059\n",
      "Epoch 4/20\n",
      "505/505 [==============================] - 0s 699us/step - loss: 1.7016 - val_loss: 1.5255\n",
      "Epoch 5/20\n",
      "505/505 [==============================] - 0s 728us/step - loss: 1.6662 - val_loss: 1.7018\n",
      "Epoch 6/20\n",
      "505/505 [==============================] - 0s 849us/step - loss: 1.6537 - val_loss: 1.6180\n",
      "Epoch 7/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 1.6377 - val_loss: 1.5247\n",
      "Epoch 8/20\n",
      "505/505 [==============================] - 0s 703us/step - loss: 1.6322 - val_loss: 1.4796\n",
      "Epoch 9/20\n",
      "505/505 [==============================] - 0s 705us/step - loss: 1.6316 - val_loss: 1.4919\n",
      "Epoch 10/20\n",
      "505/505 [==============================] - 0s 703us/step - loss: 1.6198 - val_loss: 1.4693\n",
      "Epoch 11/20\n",
      "505/505 [==============================] - 0s 702us/step - loss: 1.6142 - val_loss: 1.5113\n",
      "Epoch 12/20\n",
      "505/505 [==============================] - 0s 697us/step - loss: 1.6099 - val_loss: 1.5120\n",
      "Epoch 13/20\n",
      "505/505 [==============================] - 0s 701us/step - loss: 1.6069 - val_loss: 1.5479\n",
      "Epoch 14/20\n",
      "505/505 [==============================] - 0s 764us/step - loss: 1.6071 - val_loss: 1.4841\n",
      "Epoch 15/20\n",
      "505/505 [==============================] - 0s 703us/step - loss: 1.5909 - val_loss: 1.4358\n",
      "Epoch 16/20\n",
      "505/505 [==============================] - 0s 706us/step - loss: 1.6021 - val_loss: 1.4930\n",
      "Epoch 17/20\n",
      "505/505 [==============================] - 0s 700us/step - loss: 1.5972 - val_loss: 1.4894\n",
      "Epoch 18/20\n",
      "505/505 [==============================] - 0s 701us/step - loss: 1.5950 - val_loss: 1.5783\n",
      "Epoch 19/20\n",
      "505/505 [==============================] - 0s 732us/step - loss: 1.5940 - val_loss: 1.5261\n",
      "Epoch 20/20\n",
      "505/505 [==============================] - 0s 701us/step - loss: 1.5824 - val_loss: 1.4381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a4888250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile( loss = \"mse\", optimizer=\"adam\" )\n",
    "model.fit(x= x_train, y = y_train, validation_split=0.1, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572210a-e7fa-4d66-988c-ca8686b132b5",
   "metadata": {},
   "source": [
    "적당히 로스가 줄어들면서 학습이 되는듯하지만 일정 수준이하로는 줄 지 않는다. 특히 평균 1.5 정도의 오차는 생각보다 크다.\n",
    "\n",
    "test 데이터에 대해서 확인 후 정분류율(accuracy)를 계산해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d3dbdf-d5de-4b70-a41b-7c00bdbd0ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 457us/step\n"
     ]
    }
   ],
   "source": [
    "predicted_value = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89592657-2d22-415c-ac20-e7ee57f16f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = wrong = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == round(predicted_value[i][0]):\n",
    "        correct = correct+1\n",
    "    else:\n",
    "        wrong = wrong + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce7184d2-3a6a-4b79-afbd-96708ea15e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.37988640160374204\n"
     ]
    }
   ],
   "source": [
    "print( \"accuracy : \" , (correct) / (correct+wrong) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092f8a6-41e4-4fbc-8cfd-d2240b160470",
   "metadata": {},
   "source": [
    "생각보다 처참하다. 3개중 1개를 맞추는 거니, 그냥 찍어도 33% 가 나와야하는데, 그보다 아주 살짝 높은 정도의 성능이다. -- 찍기보다 아주 살짝 좋은 정도인데, 이걸 분류기로 사용할 수 는 없겠다. 왜 이렇게 됬는지 예측 결과의 분포를 보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39af278e-2965-435f-9c9c-df3d0a2fb186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   1.,   0.,   3.,   6.,   5.,   9.,   9.,  15.,  15.,  21.,\n",
       "         36.,  30.,  41.,  47.,  48.,  50.,  49.,  63.,  67.,  63.,  58.,\n",
       "         65.,  55.,  45.,  42.,  31.,  31.,  39.,  27.,  22.,  38.,  22.,\n",
       "         44.,  49.,  45.,  69.,  76.,  95.,  86., 110., 138., 140., 128.,\n",
       "        144., 134., 163., 131.,  99., 107.,  57.,  39.,  30.,  20.,   7.,\n",
       "          8.,  13.,   3.,   0.,   1.,   1.,   0.,   0.,   1.]),\n",
       " array([-1.88433647e-01,  4.73590195e-03,  1.97905451e-01,  3.91075015e-01,\n",
       "         5.84244549e-01,  7.77414083e-01,  9.70583677e-01,  1.16375315e+00,\n",
       "         1.35692275e+00,  1.55009234e+00,  1.74326181e+00,  1.93643141e+00,\n",
       "         2.12960100e+00,  2.32277060e+00,  2.51593995e+00,  2.70910954e+00,\n",
       "         2.90227914e+00,  3.09544873e+00,  3.28861833e+00,  3.48178768e+00,\n",
       "         3.67495728e+00,  3.86812687e+00,  4.06129646e+00,  4.25446606e+00,\n",
       "         4.44763565e+00,  4.64080524e+00,  4.83397484e+00,  5.02714396e+00,\n",
       "         5.22031355e+00,  5.41348314e+00,  5.60665274e+00,  5.79982233e+00,\n",
       "         5.99299192e+00,  6.18616152e+00,  6.37933111e+00,  6.57250071e+00,\n",
       "         6.76567030e+00,  6.95883989e+00,  7.15200901e+00,  7.34517860e+00,\n",
       "         7.53834820e+00,  7.73151779e+00,  7.92468739e+00,  8.11785698e+00,\n",
       "         8.31102657e+00,  8.50419617e+00,  8.69736576e+00,  8.89053535e+00,\n",
       "         9.08370495e+00,  9.27687454e+00,  9.47004414e+00,  9.66321373e+00,\n",
       "         9.85638332e+00,  1.00495529e+01,  1.02427216e+01,  1.04358912e+01,\n",
       "         1.06290607e+01,  1.08222303e+01,  1.10153999e+01,  1.12085695e+01,\n",
       "         1.14017391e+01,  1.15949087e+01,  1.17880783e+01,  1.19812479e+01,\n",
       "         1.21744175e+01], dtype=float32),\n",
       " <BarContainer object of 64 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted_value, bins=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39d22f-4ce4-47fc-9638-72b61e8eeaca",
   "metadata": {},
   "source": [
    "3언저리와 8,9 언저리를 분류하려는 시도는 한거 같은데, 도무지 8과 9를 구분하지 못한다. 게다가 2, 5 같은 넓은 분포가 나오는데, 예를들어 예측값이 2.312 뭐 이런값이 나왔다면 이게 3의 분포에서부터 나왔다고 판단하는게 적합하겠지만, 우리는 이걸 분류할때 반올림을 하니까 이게 2로 가서 붙어서 대충 잘 예측했음에도 불구하고 정확한 값이 나오지는 않는다... 분류기 성능을 좀 더 올릴 필요가 있다. 역시 분류기 성능 올리는 여러 방법중에 가장 우선적으로 시도해볼만한 것은 non-linearity 를 추가하는 activation 함수를 추가하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bda27813-641a-4590-b137-aff5c90aa587",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dense(16, activation='relu'), ## change it later\n",
    "        keras.layers.Dense(1)\n",
    "    ]           \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f442f58-c417-44c6-9ea5-946fc28e3157",
   "metadata": {},
   "source": [
    "거의 똑같은 모델에 relu 함수만 추가했다. 이제 똑같이 학습해서 결과를 보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf66858-e948-47d3-a69c-c1d3f664de4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51297 (200.38 KB)\n",
      "Trainable params: 51297 (200.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "505/505 [==============================] - 1s 845us/step - loss: 3.3090 - val_loss: 1.6606\n",
      "Epoch 2/20\n",
      "505/505 [==============================] - 0s 712us/step - loss: 1.4404 - val_loss: 1.1368\n",
      "Epoch 3/20\n",
      "505/505 [==============================] - 0s 715us/step - loss: 1.0899 - val_loss: 1.1379\n",
      "Epoch 4/20\n",
      "505/505 [==============================] - 0s 826us/step - loss: 0.9283 - val_loss: 0.8758\n",
      "Epoch 5/20\n",
      "505/505 [==============================] - 0s 728us/step - loss: 0.8386 - val_loss: 0.7940\n",
      "Epoch 6/20\n",
      "505/505 [==============================] - 0s 785us/step - loss: 0.7446 - val_loss: 0.7373\n",
      "Epoch 7/20\n",
      "505/505 [==============================] - 0s 757us/step - loss: 0.6666 - val_loss: 0.6819\n",
      "Epoch 8/20\n",
      "505/505 [==============================] - 0s 713us/step - loss: 0.6200 - val_loss: 0.6979\n",
      "Epoch 9/20\n",
      "505/505 [==============================] - 0s 712us/step - loss: 0.5664 - val_loss: 0.7549\n",
      "Epoch 10/20\n",
      "505/505 [==============================] - 0s 761us/step - loss: 0.5105 - val_loss: 0.5548\n",
      "Epoch 11/20\n",
      "505/505 [==============================] - 0s 705us/step - loss: 0.4685 - val_loss: 0.5512\n",
      "Epoch 12/20\n",
      "505/505 [==============================] - 0s 704us/step - loss: 0.4426 - val_loss: 0.5372\n",
      "Epoch 13/20\n",
      "505/505 [==============================] - 0s 711us/step - loss: 0.4181 - val_loss: 0.6845\n",
      "Epoch 14/20\n",
      "505/505 [==============================] - 0s 744us/step - loss: 0.3964 - val_loss: 0.5236\n",
      "Epoch 15/20\n",
      "505/505 [==============================] - 0s 710us/step - loss: 0.3614 - val_loss: 0.5291\n",
      "Epoch 16/20\n",
      "505/505 [==============================] - 0s 710us/step - loss: 0.3573 - val_loss: 0.4766\n",
      "Epoch 17/20\n",
      "505/505 [==============================] - 0s 768us/step - loss: 0.3369 - val_loss: 0.4843\n",
      "Epoch 18/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 0.3212 - val_loss: 0.4427\n",
      "Epoch 19/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 0.2989 - val_loss: 0.5010\n",
      "Epoch 20/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 0.2938 - val_loss: 0.4770\n",
      "94/94 [==============================] - 0s 446us/step\n",
      "accuracy :  0.7895088539926495\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile( loss = \"mse\", optimizer=\"adam\" )\n",
    "model.fit(x= x_train, y = y_train, validation_split=0.1, epochs=20)\n",
    "predicted_value = model.predict(x_test)\n",
    "correct = wrong = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == round(predicted_value[i][0]):\n",
    "        correct = correct+1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "print( \"accuracy : \" , (correct) / (correct+wrong) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0df4f-18d8-4495-ac17-5819e5c07e5e",
   "metadata": {},
   "source": [
    "정답율이 80% 정도로 성능이 월등히 향상되었다. activation 함수를 하나 넣었을 뿐인데 놀라울만큼 결과가 향상된다. relu 가 학습이 빨라서 자주 사용되지만, relu 외 다른 함수를 넣어도 괜찮다. 예를들어 tanh 를 넣고 돌리면 0 근처에선 linear 하고 큰 값에서는 bounded 된 값을 보여주기 때문에 이런 경우 나쁘지 않다.\n",
    "\n",
    "이제 이 분류기로 예측한 결과의 분포를 보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e66560-3c6d-4d47-aff5-b63d57cbdb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   0.,   1.,   0.,   0.,   4.,   4.,   3.,   6.,  25.,  74.,\n",
       "        198., 262., 166.,  99.,  42.,  26.,   9.,  12.,  10.,  12.,   7.,\n",
       "         11.,   6.,   4.,   3.,   4.,   2.,   6.,   5.,   4.,   2.,   3.,\n",
       "          1.,   4.,   6.,  10.,   8.,  11.,  16.,  20.,  34.,  37.,  56.,\n",
       "         53.,  93., 127., 125., 145., 116.,  99.,  80., 135., 167., 255.,\n",
       "        206., 103.,  44.,  12.,   7.,   4.,   4.,   1.,   2.]),\n",
       " array([ 1.2851954,  1.4222397,  1.5592841,  1.6963284,  1.8333728,\n",
       "         1.9704171,  2.1074615,  2.244506 ,  2.3815503,  2.5185945,\n",
       "         2.655639 ,  2.7926834,  2.9297276,  3.066772 ,  3.2038164,\n",
       "         3.3408606,  3.477905 ,  3.6149495,  3.7519937,  3.889038 ,\n",
       "         4.0260825,  4.163127 ,  4.3001714,  4.4372153,  4.5742598,\n",
       "         4.711304 ,  4.8483486,  4.985393 ,  5.1224375,  5.2594814,\n",
       "         5.396526 ,  5.5335703,  5.6706147,  5.807659 ,  5.9447036,\n",
       "         6.081748 ,  6.218792 ,  6.3558364,  6.492881 ,  6.6299253,\n",
       "         6.7669697,  6.904014 ,  7.041058 ,  7.1781025,  7.315147 ,\n",
       "         7.4521914,  7.589236 ,  7.72628  ,  7.863324 ,  8.000369 ,\n",
       "         8.137413 ,  8.274458 ,  8.411502 ,  8.548546 ,  8.685591 ,\n",
       "         8.822635 ,  8.95968  ,  9.096724 ,  9.2337675,  9.370812 ,\n",
       "         9.507856 ,  9.644901 ,  9.781945 ,  9.91899  , 10.056034 ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 64 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted_value, bins=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd41bd-82bb-4b58-a26e-79f981807bbb",
   "metadata": {},
   "source": [
    "히스토그램으로부터 몇가지를 생각해볼만하다\n",
    "\n",
    "\n",
    "1. <b>mean square error 가 이런 분류 문제에 적합한 것일까?\n",
    "\n",
    "    mse 는  (실제값-예측값)^2 을 사용한다. 근데,  우리는 8을 8으로 예측하는게 맞고, 8을 3로 예측하든, 8을 9로 예측하든 틀린건 매한가지인데, mse 입장에서는 맞게 예측했을때의 loss 는 (8-8)^2 니까 0 이지만, 틀렸을 때에는 3으로 예측해서 틀렸을때와, 9로 예측해서 틀렸을때 값이 다르다.\n",
    "\n",
    "    - 8을 3으로 잘못 예측했을 때의 loss = (8-3)^2 = 25\n",
    "    - 8을 9로 잘못 예측했을 때의 loss = (8-9)^2 = 1\n",
    "\n",
    "    즉 우리는 이리틀리나, 저리틀리나 같은 loss 를 주고 싶은데, 분류기 입장에서는 3으로 틀리는것보다 9로 틀리는게 패널티가 더 적기 때문에 3으로 예측하기보다는 아무리 3인거 같아도 적당이 어중간한 값을 선호하게 된다. 즉 중간정도에 값을 자꾸 뱉어내려는 경향이 생긴다. -> 분포에서 원래 없던 4, 5, 6, 7 사이의 값들이 자꾸 나오는 이유\n",
    "\n",
    "3. <b>그 실수값에 반올림하는게 맞나?\n",
    "\n",
    "   예를들어 위 분포에서 3.9 라는 값이 나왔다면, 그건 아마도 \"3\" 을 예측했을 것이다라는걸 쉽게 알 수 있다. 다만 3.9 라는 값을 반올림하면 4가 되는데, 우리는 애초에 4라는 값을 기대한 적도 없었다. 따라서 최종 적으로 나온 값이 어떤 분포에서 부터 나왔을 것이다라는걸 (확률적으로) 추정해야하는데 이걸 하기에 반올림은 적합하지 않다.\n",
    "\n",
    "\n",
    "## 따라서 분류 문제에서는 회귀 문제와 다르게 다음의 2가지 테크닉을 사용한다.\n",
    "\n",
    "1.  One-hot encoding 을 사용해서 각 category 를 n 개의 dummy variable 로 만든다.\n",
    "\n",
    "2.  softmax 를 사용해서 최종 출력값을 마치 확률처럼 변환한다.\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8568fe8-766b-4086-bab9-63199eb374f5",
   "metadata": {},
   "source": [
    "실제 onehot encoding 이 어떻게 진행되는지 코드를 보면 직관적으로 이해가 된다. keras 에서도 categorical encoder 를 제공하지만, 이해를 돕기 위해서 여기서는 scikit-learn 의 onehot encoder 를 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b4f6e5-3b86-4ba9-bdd6-cd3d5e953091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder # 필요한 페키지를 로드하고\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore') #원핫 인코더를 생선한다. ignore 옵션은 나중에 역변환 할떄 에러를 방지하기위한 옵션이다.\n",
    "\n",
    "y_train= y_train.reshape(-1,1) #scikit learn 은 들어가는 모든애들이 2차원 (dataframe형식) 이어야 해서 format 을 맞춰줘야한다.\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "X = [3, 8, 9] # 내가 가진 범주는 아래와 같이 3개가 있다고 알려주고\n",
    "\n",
    "enc.fit( np.array(X).reshape(-1, 1) ) # 인코더를 학습(fit) 시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e4fea4-6025-4ef4-930c-74df66873ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = enc.transform(y_train).toarray() #학습된 인코더로 y_label 을 변환(tranform) 한다. \n",
    "y_test_onehot = enc.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77e653-5fd0-4280-8098-c105721bc212",
   "metadata": {},
   "source": [
    "인코더로 변환된 값은 아래처럼 더미 변수에 각각 0 또는 1이 들어간 식으로 변환이 된다. 처음 10개의 label 이 어떻게 변했는지 확인해보면 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72aff9b4-4aa1-48f8-8aa0-ce64496f8b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]  ==>  [0. 0. 1.]\n",
      "[3]  ==>  [1. 0. 0.]\n",
      "[3]  ==>  [1. 0. 0.]\n",
      "[3]  ==>  [1. 0. 0.]\n",
      "[8]  ==>  [0. 1. 0.]\n",
      "[9]  ==>  [0. 0. 1.]\n",
      "[9]  ==>  [0. 0. 1.]\n",
      "[3]  ==>  [1. 0. 0.]\n",
      "[3]  ==>  [1. 0. 0.]\n",
      "[8]  ==>  [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print( y_train[i],  \" ==> \" , y_train_onehot[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fec9d9-ab1a-491d-949c-d7e9183a0232",
   "metadata": {},
   "source": [
    "위와 같이 3 은 (1, 0, 0) 으로,  8 은 (0, 1, 0) 으로, 그리고 9 는 (0, 0, 1) 로 변환이 된다. 어차피 더미로 만들어진 변수이므로 순서나 그런건 중요하지 않다. 일관적으로 모든 3은 (1, 0, 0) 으로 변환되고 9는 (0, 0, 1) 로 변환된다는 사실만 중요하지 (나중에 역변환을 하려면 이 규칙이 필요하긴하다.) \n",
    "\n",
    "이 3개의 더미 변수는 각각 3이냐 8이냐 9냐를 뜻하는 확률 분포로 해석해도 된다. \n",
    "\n",
    "예를들어 3 = [1, 0, 0] 이라면\n",
    "\n",
    "[0.9, 0.0, 0.1] 은  3일 확률은 90%, 9일 확률은 10% 라는 식으로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adab4a9-a8cf-484c-9caa-3c5331c2dee8",
   "metadata": {},
   "source": [
    "최종 답안지를 위처럼 3개의 dummy 변수로 만들었으니, 이제 우리 모델도 최종적으로 뱉어야 하는 값은 3개다. \n",
    "\n",
    "마지막에 확률 비스무리하게 만들어야 하니, softmax 라는 activation 함수를 사용한다. 이 함수는 3개의 값의 합이 1이 되도록 변환해주며 변환하는 수식은 다음과 같다.\n",
    "\n",
    "https://ko.wikipedia.org/wiki/%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4_%ED%95%A8%EC%88%98\n",
    "(한글 위키는 뭔가 이상하다... 여기를 참조하는게 좋을 듯 https://en.wikipedia.org/wiki/Softmax_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa8c9620-5703-4b43-b191-56306832711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51331 (200.51 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 51331 (200.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28)\n",
    "\n",
    "model2 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dense(16),\n",
    "        keras.layers.Dense(3, activation='softmax') ## softmax ->  합이 1이 되게 바꿔주는 함수 \n",
    "    ]           \n",
    ")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4579d5-ffb7-40bd-8b99-013354524208",
   "metadata": {},
   "source": [
    "이제 모델을 컴파일해보자. 이제 최종 출력단이 바뀌었으므로, 로스함수도 같이 바뀌어야 한다.\n",
    "전에는 1개의 값에 대해서 (실제값-예측값) 의 차이를 썼지만, 지금은 최종단이 3개의 노드에 대한 확률분포이므로 확률 분포간의 차이를 로스로 써야하는게 인지상정! 이런 경우에 사용하는게 크로스엔트로피이다. 용어는 어려워 보이지만, 사실 loss 수식은 굉장히 간단한데 (https://en.wikipedia.org/wiki/Cross-entropy) \n",
    "\n",
    "그냥 간단하게 이야기하면\n",
    "\n",
    "정답 분포를 얼마나 자신있게 맞추었냐이다.\n",
    "\n",
    "[0, 1, 0] 이 정답인데, 이걸 [0.2, 0.5, 0.3] 으로 예측했다면 맞추긴 했다고 할 수 있지만 (가운데가 제일 높으니까) 그래도 완벽하진 않다. 이경우에는 \n",
    "\n",
    "-log(0.5) 만큼 로스가 발생한다.  \n",
    "\n",
    "반면에 [0.1, 0.9, 0] 으로 예측했다면 거의 정답에 가깝게 예측했다고 할 수 있다. 이 경우에는\n",
    "\n",
    "-log(0.9) 만큼 로스가 발생한다.\n",
    "\n",
    "앞에 -부호가 있으므로 로스는 후자가 더 적다. 모델은 어찌됬든 로스를 작게 만드는게 학습의 목적이므로, 정점 정답 분포에 가깝게 갈 것이다. 따라서 원핫 인코딩된 확률 분포를 닮게 만들고 싶다면 cross entropy 를 손실함수로 사용하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28b38c7e-9c5b-4fef-8c27-e374dcdb2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "505/505 [==============================] - 1s 850us/step - loss: 0.1778 - val_loss: 0.1350\n",
      "Epoch 2/20\n",
      "505/505 [==============================] - 0s 702us/step - loss: 0.1343 - val_loss: 0.1298\n",
      "Epoch 3/20\n",
      "505/505 [==============================] - 0s 698us/step - loss: 0.1261 - val_loss: 0.1028\n",
      "Epoch 4/20\n",
      "505/505 [==============================] - 0s 841us/step - loss: 0.1238 - val_loss: 0.1217\n",
      "Epoch 5/20\n",
      "505/505 [==============================] - 0s 743us/step - loss: 0.1185 - val_loss: 0.1135\n",
      "Epoch 6/20\n",
      "505/505 [==============================] - 0s 821us/step - loss: 0.1152 - val_loss: 0.1074\n",
      "Epoch 7/20\n",
      "505/505 [==============================] - 0s 743us/step - loss: 0.1161 - val_loss: 0.1088\n",
      "Epoch 8/20\n",
      "505/505 [==============================] - 0s 706us/step - loss: 0.1124 - val_loss: 0.0995\n",
      "Epoch 9/20\n",
      "505/505 [==============================] - 0s 744us/step - loss: 0.1127 - val_loss: 0.1013\n",
      "Epoch 10/20\n",
      "505/505 [==============================] - 0s 702us/step - loss: 0.1102 - val_loss: 0.1054\n",
      "Epoch 11/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 0.1109 - val_loss: 0.1020\n",
      "Epoch 12/20\n",
      "505/505 [==============================] - 0s 706us/step - loss: 0.1073 - val_loss: 0.1034\n",
      "Epoch 13/20\n",
      "505/505 [==============================] - 0s 702us/step - loss: 0.1080 - val_loss: 0.1109\n",
      "Epoch 14/20\n",
      "505/505 [==============================] - 0s 702us/step - loss: 0.1074 - val_loss: 0.0997\n",
      "Epoch 15/20\n",
      "505/505 [==============================] - 0s 701us/step - loss: 0.1061 - val_loss: 0.0987\n",
      "Epoch 16/20\n",
      "505/505 [==============================] - 0s 707us/step - loss: 0.1060 - val_loss: 0.1098\n",
      "Epoch 17/20\n",
      "505/505 [==============================] - 0s 761us/step - loss: 0.1047 - val_loss: 0.1036\n",
      "Epoch 18/20\n",
      "505/505 [==============================] - 0s 698us/step - loss: 0.1041 - val_loss: 0.1010\n",
      "Epoch 19/20\n",
      "505/505 [==============================] - 0s 697us/step - loss: 0.1037 - val_loss: 0.1027\n",
      "Epoch 20/20\n",
      "505/505 [==============================] - 0s 699us/step - loss: 0.1044 - val_loss: 0.0993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c9d46d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile( loss = 'categorical_crossentropy', optimizer='adam')\n",
    "model2.fit( x=x_train, y=y_train_onehot, validation_split=0.1, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39a075-6a9c-4fb3-96e3-55ec849c501f",
   "metadata": {},
   "source": [
    "학습이 되었다. mse 를 손실함수로 사용했던 과거와 다르게 이제 로스가 cross entropy 이므로 직관적으로 이게 얼마나 잘된건지 이해하긴 힘들다. 다만 loss 가 충분히 줄었다는 트렌드만 확인할 수 있으면 된다. 이제 이 모델로 예측을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d05a0e8b-0387-4719-ab7a-3b76b5d3daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 459us/step\n"
     ]
    }
   ],
   "source": [
    "predicted_value = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791f776-94e0-41c7-8b07-dc71babf8815",
   "metadata": {},
   "source": [
    "모델의 최종단이 바뀌었기 때문에 (3개의 노드 출력, 합은 1) 최종 예측값도 아래처럼 3개가 한쌍이 되서 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d5ee26-0366-425f-b998-e6b3bff6cee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1893775e-06, 6.8065834e-05, 9.9992979e-01],\n",
       "       [1.7853539e-08, 1.8671020e-05, 9.9998128e-01],\n",
       "       [3.1821377e-04, 8.6501735e-05, 9.9959534e-01],\n",
       "       ...,\n",
       "       [4.9306364e-03, 9.9506420e-01, 5.1903812e-06],\n",
       "       [1.3639410e-08, 2.4266742e-06, 9.9999762e-01],\n",
       "       [9.9999964e-01, 3.1202842e-07, 2.1544585e-08]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01017501-8a71-4e2e-b178-cb82ffa29987",
   "metadata": {},
   "source": [
    "각각 3개의 분포중에 어디에 해당하는지를 확률적으로 나타내는 것이므로, 이 중에서 가장 큰 값을 1로, 나머지는 0으로 만들어야 한다. (원래는 numpy 의 argmax를 써야 하지만, 그냥 직관적으로 젤 큰값 -> 0.5보다 클거다라고 가정하고 반올림 처리를 해서 진행하자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "649bf7f7-d12e-4e8a-80e6-826c90d24577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "predicted_value_onehot = np.round(predicted_value)\n",
    "print(predicted_value_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec37850-50d4-47d7-bb54-16f0b2a96475",
   "metadata": {},
   "source": [
    "실제 답안지와 비교를 하기 위해서 저 분포를 다시 one-hot encoding 되기 전의 규칙으로 돌려보자 \n",
    "\n",
    "[1, 0, 0] ==> 3 <br>\n",
    "[0, 1, 0] ==> 8 <br>\n",
    "[0, 0, 1] ==> 9 <br>\n",
    "\n",
    "아까 원핫인코더의 inverse transform 을 하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d10bd82d-5f20-4dde-b4b2-4db52ed507bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [8],\n",
       "       [9],\n",
       "       [3]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_number = enc.inverse_transform(predicted_value_onehot)\n",
    "predicted_number "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ffb995-1db3-4e98-8b92-1ccecaae282f",
   "metadata": {},
   "source": [
    "이제 정답지와 비교해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f4e22a4-a250-47ed-9df0-38c3325cdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = wrong = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == predicted_number[i][0]:\n",
    "        correct = correct+1\n",
    "    else:\n",
    "        wrong = wrong + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "697613bf-4dae-46c2-982a-e05cc5e0e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605746742398931\n"
     ]
    }
   ],
   "source": [
    "accuracy = (correct) / (correct+wrong)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cf31f-23f5-43b0-ae96-64cb673e39b5",
   "metadata": {},
   "source": [
    "거의 같은 모델인데도 불구하고 96% 에 가까운 정분류율을 보여준다. \n",
    "\n",
    "앞서 이야기 했지만 분류율이 이렇게 획기적으로 올라간 이유는\n",
    "\n",
    "1. 손실함수를 제대로 설정해줬기 때문에 --> 8과 9 를 예측하는데 MSE 를 쓰면 8.4, 8.6 같은 애매한 값을 자꾸 뱉으려고 노력한다. 심하게 질렀다가 틀리면 패널티가 크니까 (점수는 올라가는데 자신감이 떨어지는 현상) 따라서 맞추는거 + 얼마나 자신있게 지르느냐 둘 다를 고려한 확률 분포의 차이를 손실함수로 사용하는게 맞다.\n",
    "\n",
    "2. 최종적으로 나온 값을 제대로 값으로 분류하기 위해 최종단을 확률분포로 받고, 이중에서 제일 높은 값을 정답으로 취하는 정책을 취했기 때문에\n",
    "\n",
    "이렇게 정리할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
