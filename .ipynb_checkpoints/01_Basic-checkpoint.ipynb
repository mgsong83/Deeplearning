{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd02b7d6-f1a5-464a-9773-cd7e59d55058",
   "metadata": {},
   "source": [
    "## 필수 패키지 로드 \n",
    "만약 package 가 없다는 에러가 발생하면 pip install 명령어로 설치하면 된다. 아마 miniconda 를 설치했다면 아래 페키지가 한개도 없을 가능성이 크기 때문에\n",
    "pip install torch pandas matplotlib torchvision torchinfo torch_lightning 등을 다 해줘야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a93338-4ca6-4935-8691-9ab9236432bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.1+cpu', '2.0.8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.accelerators import accelerator\n",
    "from torchmetrics import functional as FM\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5, 3.5]\n",
    "plt.rcParams[\"font.size\"] = \"8\"\n",
    "\n",
    "torch.__version__,pl.__version__,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b6501-9cc7-4646-b81e-03bfdec60d61",
   "metadata": {},
   "source": [
    "## Dataset 준비\n",
    "\n",
    "\n",
    "뭐니뭐니 해도 가장 기본적인 데이터는 국민 딥러닝 데이터인 손글씨 (MNIST) 일 것이다. 데이터에 대해서 잠시 설명하자면 28x28 pixel 사이즈로 쓰여진 손 글씨를 흑백 파일로 만든 것이다.\n",
    "흑백이기 때문에 RGB 이미지와 달리 채널은 1개뿐이고, 사이즈는 28 x 28 로 이루어져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72de868f-8fcb-4581-bf78-7a2877fe1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:01<00:00, 5568144.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 28924473.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 1826132.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def dataLoader(batch_size=128):\n",
    "    train_dataset = MNIST('', transform=transforms.ToTensor(), train=True, download=True) ## 한 번 인터넷으로 가져온걸 매번 가져올 필요가 없기 때문에 가져올때 download True 로 하면 다음 부터는 다운로드 된 데이터를 사용한다.\n",
    "    test_dataset = MNIST('', transform=transforms.ToTensor(), train=False, download=True)\n",
    "    trainDataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valDataLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return (trainDataLoader,valDataLoader)\n",
    "\n",
    "trainDataLoader,valDataLoader = dataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e055263-e0ea-4f44-bb2b-5c2defd67fe4",
   "metadata": {},
   "source": [
    "- transforms : pytorch 는 Tensor 라는 데이터 형을 사용하기 때문에 (numpy의 ndarray 와 비슷하지만 추가 정보가 포함되어있어서 좀 더 고차원인 데이터형식) 아예 데이터를 받으면서 tensor 형으로 변환시켜주었다.\n",
    "- download : 인터넷에서 데이터를 로드 할 때, 매번 로드할 필요없이 다운로드를 받아두면 그 다음부터는 다운로드 받은 데이터를 사용하기 때문에 속도와 네트워크 사용량에서 유리하다\n",
    "\n",
    "받아진 데이터를 쉽게 핸들링하기 위해서 바로 DataLoader 에 셋업하였다. DataLoader 에 로딩된 데이터는 간단히 next(iter()) 를 통해서 데이터를 받아오고 다음으로 넘어갈 수 있다. 파이토치를 쓸 때 가장 편한 유틸이 바로 이 데이터 셋을 만들고 이걸 로더에 로딩만하면 데이터를 학습할때 굳이 데이터 위치를 일일이 설정해줄 필요가 없다는 점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb8c2d7-f71b-447a-9bfd-587411c361b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST('', transform=transforms.ToTensor(), train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0098c903-4410-431a-8905-1f768dc8c518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: \n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_data) ## 6만개의 손글씨 데이터 셋\n",
    "#train_data[0] ## 중에서 첫번째  (이미지 + 라벨)\n",
    "#train_data[0][0] ## 중에서 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678d1776-368f-4e25-890f-008d618724bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data[0][0].shape)\n",
    "plt.imshow(train_data[0][0].view((28,28))) ##  tensor 에서는 reshape 대신 view 를 쓴다. 물론 reshape 도 되기는 하는데, 전통적으로 view 를 더 많이 쓰는듯.\n",
    "print( train_data[0][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be5971-85af-494c-aba1-439c10af97b2",
   "metadata": {},
   "source": [
    "###  Model 정의 \n",
    "\n",
    "이제 데이터가 준비되었으니, 아주 간단한 모델을 만들어보자. 모델이 할 일은 다음과 같다. \n",
    "\n",
    "1. 손글씨 데이터를 읽어서\n",
    "2. 28 * 28 을 기다란 784 vector 로 만든 뒤에\n",
    "3. Fully connected 된 1개의 layer를 통해서\n",
    "4. 0~10 을 예측하는 layer로 전달하고 \n",
    "5. 이걸 onehot encode 된 실제 y와 비교하여\n",
    "6. loss 를 계산하여, 이 loss가 최소가 되도록!\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adb9ed11-2be7-4245-bbca-1f151b70d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss() ## 회귀가 아닌 분류의 문제이므로 cross entropy 를 loss 로 사용한다. \n",
    "\n",
    "class mymodel1( pl.LightningModule ):  ## torch 또는 torch_lightning 의 기본 모듈을 상속받아서 사용한다. torch_lightning 이 좀 더 편하므로 왠만하면 lihgtning 을 상속\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(  ## forward 에서 이리저리 연결해주는 방법보다. 그냥 순차적인 layer 하나 넣주는게 여러모로 편함.\n",
    "            nn.Flatten(),\n",
    "            nn.Linear( 28*28, 10 ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6670e-6a80-445f-9a5d-e35388bd101b",
   "metadata": {},
   "source": [
    "이렇게 기본적인 뼈대가 만들어졌다. 물론 아직 이대로는 돌아가지 않는다. torch_lightning 은 보통 Trainer 를 통해서 학습하게 되는데, Trainer 에 물리기 위해서는 다음의 매쏘드가 정의되어야 한다.\n",
    "\n",
    "1. training_step : 학습을 진행할 때 (~ train loop 에서 하는 일)\n",
    "2. validation_step : 검증을 진행할 때 (위와 같지만 굳이 loss return 필요없음)\n",
    "3. test_step : 테스트를 진행할 때 (위와 같고 역시 loss retrun 필요없음)\n",
    "4. configure_optimizer : 옵티마이져에 대한 셋팅\n",
    "\n",
    "이것만 정의하면 되고, 굳이 torch 에서 처럼 x.to(device), x.cuda() 이런거는 다 자동으로 이루어진다! (세상에!)\n",
    "심지어 학습만 하고 검증/예측을 안할꺼라면 그냥 1, 4만 구현해도 된다.\n",
    "\n",
    "그래도 검증까지는 필요하니까 train / valid step 을 정의하고 optimizer 를 정의해서 모델을 완료시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4442dba5-11d9-4097-ad58-dc21b74cde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class mymodel2( mymodel1 ): \n",
    "\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "        acc = FM.accuracy(y_pred, y, task=\"multiclass\",num_classes=10)\n",
    "        self.log_dict({'loss':loss, 'acc':acc})\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "        acc = FM.accuracy(y_pred, y, task=\"multiclass\",num_classes=10)\n",
    "        self.log_dict({'val_loss':loss, 'val_acc':acc})\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1d2fd60-8082-49a8-b9aa-f5f656012c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "mymodel2                                 [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 10]                   --\n",
       "│    └─Flatten: 2-1                      [1, 784]                  --\n",
       "│    └─Linear: 2-2                       [1, 10]                   7,850\n",
       "==========================================================================================\n",
       "Total params: 7,850\n",
       "Trainable params: 7,850\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.03\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mm = mymodel2()\n",
    "summary(mm, input_size = (1, 1, 28, 28)) ## 들어갈때 batch size와 channel 을 알려줘야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3a09a-56f7-4a34-b799-836e55b3024a",
   "metadata": {},
   "source": [
    "이대로도 학습은 잘 진행된다. 3회만 학습을 돌려보자. accelerator 를 auto 로 두면 GPU 가 있고 cuda 가 깔려있을 경우 알아서 스스로 GPU 가속을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d3f9228-361c-4b02-a0b9-db7b7db4a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | layers | Sequential | 7.9 K \n",
      "--------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc56ae0b59248f7b945ef7502537e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 46s\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 3\n",
    "trainer = pl.Trainer(max_epochs=epochs,accelerator=\"auto\")\n",
    "trainer.fit(mm, trainDataLoader, valDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4ee3f-78ec-4ec6-aeae-2297aca8ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b8658-1e8f-4d9a-8882-2f15d75f1c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
