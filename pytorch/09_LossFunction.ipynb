{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df093f07-ff15-4ff0-b43c-559337985dea",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "딥러닝의 핵심은 주어진 네트워크의 weight bias를 loss 가 작아지는 쪽으로 바꾸는 데 있다. 따라서 손실함수야 말로 학습을 어떻게 할 지 정의해주는 부분이라고 생각 할 수 있다. \n",
    "\n",
    "pytorch / pytorch lightning 에서는 기본적으로 회귀에서 사용되는 MSE, 분류에서 사용되는 Cross Entropy 뿐 아니라 다양한 손실함수를 정의하고 있으며, 이는 torch.nn.functional 에 사전 정의되어 내장되어 있다. \n",
    "\n",
    "> torch.nn.functional\n",
    "* mse_loss      : element-wise mean squared error.\n",
    "* cross_entropy : cross entropy loss between input(logit) and target(prob.).\n",
    "* binary_cross_entropy : Binary Cross Entropy between the target and input probabilities.\n",
    "* binary_cross_entropy_with_logits :  Binary Cross Entropy between target and input logits.\n",
    "* kl_div : Kullback-Leibler divergence Loss\n",
    "* l1_loss : mean element-wise absolute value difference.\n",
    "* smooth_l1_loss : uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.\n",
    "* nll_loss : negative log likelihood loss.\n",
    "* poisson_nll_loss : Poisson negative log likelihood loss.\n",
    "* gaussian_nll_loss : Gaussian negative log likelihood loss.\n",
    "\n",
    "\n",
    "또한 Metric 들도 다양하게 사용할 수 있는데, Accuracy, AUCROC 등등 torchmetrics 를 통해 사용할 수 있다.\n",
    "https://torchmetrics.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334062c1-3ec1-42a0-b05d-82f72e996389",
   "metadata": {},
   "source": [
    "대부분의 경우 내장됨 함수를 사용하게 되겠지만, 필요하다면 임의의 loss / metric 을 정의해서 쓸 수 도 있는데, 그 방법은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073d898d-779c-4ff5-8c91-8f6686bb4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.accelerators import accelerator\n",
    "from torchmetrics import functional as FM\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4307064e-752e-4479-9d3c-1a9ebb1d2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onehot(object) :\n",
    "    def __call__(self, sample):\n",
    "        sample = sample\n",
    "        target = np.eye(10)[sample] # 10x10 대각행열을 만들어서 그 중에 n번째 row 를 반환 0 --> (1,0,0,0,0....0)\n",
    "        return torch.FloatTensor(target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc23846b-d50d-42ca-9554-09b9d2e39f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Onehot()\n",
    "a(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb59b9a-b3f5-41e2-9050-7723eea7aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_transform = transforms.Compose([Onehot()])         # target one-hot encoding \n",
    "x_transform = transforms.Compose([transforms.ToTensor()])  # image transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e737a9-7d76-4ea6-bcae-74a765bbfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST('', transform=x_transform, target_transform=y_transform, train=True)\n",
    "test_dataset = MNIST('', transform=x_transform, target_transform=y_transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ef3b0-c231-42d8-ac36-9c5cd5d7b67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07247324-ee3c-4b8e-8b5c-7cf9de83392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainDatLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valDataLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76dc1ce9-5e46-47e8-953f-46e146c37d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(28*28, 64)\n",
    "        self.linear2 = nn.Linear(64, 32)\n",
    "        self.linear3 = nn.Linear(32, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x1 = self.linear1(x)\n",
    "        x1 = self.relu(x1)\n",
    "        x2 = self.linear2(x1)\n",
    "        x2 = self.relu(x2)\n",
    "        x3 = self.linear3(x2)\n",
    "        return x3\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2266195-1f01-456f-931c-94ce79dda210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_mse(pred, target):\n",
    "    error = torch.mean(torch.square(pred-target))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668e4450-416e-4ab0-a890-04f26f00acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mean_abs_error(y_pred, y_true):\n",
    "    error = torch.abs(torch.mean(y_true - y_pred))\n",
    "    return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d4dd2-3e23-473f-a4d3-8a0fc65e8ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b604824f-8eea-40e6-8988-8e38078b5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = Model()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = torch.softmax(out, dim=-1) \n",
    "        return(out)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = custom_loss_mse(y_pred, y)\n",
    "        error = custom_mean_abs_error(y_pred, y)\n",
    "        metrics = {'loss' : loss, 'error' : error}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = custom_loss_mse(y_pred, y)\n",
    "        error = custom_mean_abs_error(y_pred, y)\n",
    "        metrics = {'val_loss':loss, 'val_error':error}\n",
    "        self.log_dict(metrics)\n",
    "        #return loss # validation 은 리턴 안해도 상관 없음\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam( self.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52ff85ae-cb7f-476c-96d5-8ffcfcfaecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90d8d301-961e-4417-8348-d5e0f8574c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "myModel                                  [8, 10]                   --\n",
       "├─Model: 1-1                             [8, 10]                   --\n",
       "│    └─Flatten: 2-1                      [8, 784]                  --\n",
       "│    └─Linear: 2-2                       [8, 64]                   50,240\n",
       "│    └─ReLU: 2-3                         [8, 64]                   --\n",
       "│    └─Linear: 2-4                       [8, 32]                   2,080\n",
       "│    └─ReLU: 2-5                         [8, 32]                   --\n",
       "│    └─Linear: 2-6                       [8, 10]                   330\n",
       "==========================================================================================\n",
       "Total params: 52,650\n",
       "Trainable params: 52,650\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 0.24\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(8, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5e90009-9a63-47d3-9bdd-14bea4a53508",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "name = 'custom_loss_model' \n",
    "logger = pl.loggers.CSVLogger(\"logs\", name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "969ff3b3-aae3-4652-b79e-80f6b5f86e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type  | Params\n",
      "---------------------------------\n",
      "0 | layers | Model | 52.6 K\n",
      "---------------------------------\n",
      "52.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.6 K    Total params\n",
      "0.211     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msong\\miniconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\msong\\miniconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd2537ac86b4b9cb3fec885e90cde42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs= epoch, logger=logger, accelerator='auto')\n",
    "trainer.fit(model, trainDatLoader, valDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ad55cc4-8e62-4551-9ec0-199c28cad894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>error</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049860</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020648</td>\n",
       "      <td>8.847564e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014066</td>\n",
       "      <td>3.725290e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020123</td>\n",
       "      <td>9.313226e-11</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012650</td>\n",
       "      <td>3.725290e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021460</td>\n",
       "      <td>7.683411e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018764</td>\n",
       "      <td>1.164153e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012486</td>\n",
       "      <td>3.725290e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011867</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>4.249812e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012964</td>\n",
       "      <td>1.862645e-10</td>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009760</td>\n",
       "      <td>1.816079e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014843</td>\n",
       "      <td>2.793968e-10</td>\n",
       "      <td>1</td>\n",
       "      <td>599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009883</td>\n",
       "      <td>9.313226e-11</td>\n",
       "      <td>1</td>\n",
       "      <td>649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011117</td>\n",
       "      <td>1.117587e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013990</td>\n",
       "      <td>9.313226e-11</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.011226</td>\n",
       "      <td>1.862645e-10</td>\n",
       "      <td>1</td>\n",
       "      <td>799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.014216</td>\n",
       "      <td>2.328306e-11</td>\n",
       "      <td>1</td>\n",
       "      <td>849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013232</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>937</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>5.265187e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.010173</td>\n",
       "      <td>1.862645e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010028</td>\n",
       "      <td>2.444722e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.008454</td>\n",
       "      <td>1.862645e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.009846</td>\n",
       "      <td>1.396984e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.007617</td>\n",
       "      <td>4.423782e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.009752</td>\n",
       "      <td>3.725290e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.012203</td>\n",
       "      <td>1.396984e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008074</td>\n",
       "      <td>1.979061e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.004564</td>\n",
       "      <td>1.164153e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.008949</td>\n",
       "      <td>6.053597e-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1406</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>4.597271e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss         error  epoch  step  val_loss     val_error\n",
       "0   0.049860  2.328306e-10      0    49       NaN           NaN\n",
       "1   0.020648  8.847564e-10      0    99       NaN           NaN\n",
       "2   0.014066  3.725290e-10      0   149       NaN           NaN\n",
       "3   0.020123  9.313226e-11      0   199       NaN           NaN\n",
       "4   0.012650  3.725290e-10      0   249       NaN           NaN\n",
       "5   0.021460  7.683411e-10      0   299       NaN           NaN\n",
       "6   0.018764  1.164153e-10      0   349       NaN           NaN\n",
       "7   0.012486  3.725290e-10      0   399       NaN           NaN\n",
       "8   0.011867  6.984919e-10      0   449       NaN           NaN\n",
       "9        NaN           NaN      0   468  0.011942  4.249812e-10\n",
       "10  0.012964  1.862645e-10      1   499       NaN           NaN\n",
       "11  0.009760  1.816079e-09      1   549       NaN           NaN\n",
       "12  0.014843  2.793968e-10      1   599       NaN           NaN\n",
       "13  0.009883  9.313226e-11      1   649       NaN           NaN\n",
       "14  0.011117  1.117587e-09      1   699       NaN           NaN\n",
       "15  0.013990  9.313226e-11      1   749       NaN           NaN\n",
       "16  0.011226  1.862645e-10      1   799       NaN           NaN\n",
       "17  0.014216  2.328306e-11      1   849       NaN           NaN\n",
       "18  0.013232  2.328306e-10      1   899       NaN           NaN\n",
       "19       NaN           NaN      1   937  0.010530  5.265187e-10\n",
       "20  0.010173  1.862645e-10      2   949       NaN           NaN\n",
       "21  0.010028  2.444722e-10      2   999       NaN           NaN\n",
       "22  0.008454  1.862645e-10      2  1049       NaN           NaN\n",
       "23  0.009846  1.396984e-10      2  1099       NaN           NaN\n",
       "24  0.007617  4.423782e-10      2  1149       NaN           NaN\n",
       "25  0.009752  3.725290e-10      2  1199       NaN           NaN\n",
       "26  0.012203  1.396984e-10      2  1249       NaN           NaN\n",
       "27  0.008074  1.979061e-10      2  1299       NaN           NaN\n",
       "28  0.004564  1.164153e-10      2  1349       NaN           NaN\n",
       "29  0.008949  6.053597e-10      2  1399       NaN           NaN\n",
       "30       NaN           NaN      2  1406  0.008557  4.597271e-10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_num = logger.version\n",
    "history = pd.read_csv(f'./logs/{name}/version_{version_num}/metrics.csv')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6d00653-329b-4fc8-800e-1fbb8293c202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011867</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>4.249812e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013232</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>5.265187e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008949</td>\n",
       "      <td>6.053597e-10</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>4.597271e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss         error  val_loss     val_error\n",
       "epoch                                                \n",
       "0      0.011867  6.984919e-10  0.011942  4.249812e-10\n",
       "1      0.013232  2.328306e-10  0.010530  5.265187e-10\n",
       "2      0.008949  6.053597e-10  0.008557  4.597271e-10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.groupby('epoch').last().drop('step', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b9f21-7319-4588-be25-9c8166f92b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
